{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Leocodefocus/project/blob/master/multi_class.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Vd-yQ5c2IpUa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjWxpDG0V1lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(y_name=\"Species\"):\n",
        "  train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "  test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "  \n",
        "  train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "  test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  test_x, test_y = test, test.pop(y_name)\n",
        "  \n",
        "  return (train_x,train_y),(test_x,test_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HxiIQvkaJwP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features,labels,batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  return dataset.shuffle(1000).repeat().batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ikdOXoeSB0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features,labels,batch_size):\n",
        "  features = dict(features)\n",
        "  if labels is None:\n",
        "    inputs = features\n",
        "  else:\n",
        "    inputs = (features,labels)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "  assert batch_size is not None,\"Batch_size must not be None.\"\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_x6yxapVKEUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(train_examples):\n",
        "  my_feature_columns = []\n",
        "  for key in train_examples.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "  return my_feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZnPpNdmKk1N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(train_examples,train_targets,test_examples,test_targets,\n",
        "                batch_size,train_steps):\n",
        "  my_feature_columns = construct_feature_columns(train_examples)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns = my_feature_columns,\n",
        "      hidden_units = [10,10],\n",
        "      n_classes=3)\n",
        "  classifier.train(\n",
        "      input_fn=lambda:train_input_fn(train_examples,train_targets,batch_size),\n",
        "      steps = train_steps)\n",
        "  eval_result = classifier.evaluate(\n",
        "      input_fn=lambda:eval_input_fn(test_examples,test_targets,batch_size))\n",
        "  print(\"\\nTest set accuracy: {accuracy:0.3f}\\n\".format(**eval_result))\n",
        "  expected = SPECIES\n",
        "  predict_examples = {\n",
        "        'SepalLength': [5.1, 5.9, 6.9],\n",
        "        'SepalWidth': [3.3, 3.0, 3.1],\n",
        "        'PetalLength': [1.7, 4.2, 5.4],\n",
        "        'PetalWidth': [0.5, 1.5, 2.1],\n",
        "    }\n",
        "  predictions = classifier.predict(\n",
        "      input_fn=lambda:eval_input_fn(predict_examples,\n",
        "                                    labels = None,\n",
        "                                    batch_size = batch_size))\n",
        "  template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "  \n",
        "  for pred_dict,expec in zip(predictions,expected):\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "    \n",
        "    print(template.format(expected[class_id],100*probability,expec))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cy1zhkzSVTTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "78b4ef4f-0ce3-40ea-d978-8f0b39fa86ac"
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "(train_examples,train_targets),(test_examples,test_targets) = get_data()\n",
        "train_model(train_examples,train_targets,test_examples,test_targets,\n",
        "            batch_size=100,train_steps=1000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp73oveqcu\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp73oveqcu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2e0995f908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp73oveqcu/model.ckpt.\n",
            "INFO:tensorflow:loss = 164.80676, step = 1\n",
            "INFO:tensorflow:global_step/sec: 700.037\n",
            "INFO:tensorflow:loss = 13.640622, step = 101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.237\n",
            "INFO:tensorflow:loss = 12.290114, step = 201 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.043\n",
            "INFO:tensorflow:loss = 6.3403788, step = 301 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.512\n",
            "INFO:tensorflow:loss = 6.9456453, step = 401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 760.223\n",
            "INFO:tensorflow:loss = 5.405442, step = 501 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.34\n",
            "INFO:tensorflow:loss = 6.8535595, step = 601 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 761.94\n",
            "INFO:tensorflow:loss = 7.9709573, step = 701 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 758.556\n",
            "INFO:tensorflow:loss = 3.0527654, step = 801 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 792.299\n",
            "INFO:tensorflow:loss = 6.2996755, step = 901 (0.125 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp73oveqcu/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 8.424563.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-04-27-09:18:24\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp73oveqcu/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-04-27-09:18:24\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.053024042, global_step = 1000, loss = 1.5907212\n",
            "\n",
            "Test set accuracy: 0.967\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp73oveqcu/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "Prediction is \"Setosa\" (99.9%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Versicolor\" (99.8%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (97.7%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}